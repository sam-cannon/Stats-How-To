{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#lines below let allow multiple results from a line of code to be shown e.g. df.head() + df.columns\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Sam Cannon\\\\Desktop\\\\R\\\\Data Sets\\\\new_datasets_7e\\\\new_datasets_7e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPSS reading module, need to replace column names though\n",
    "import savReaderWriter as s\n",
    "df= pd.DataFrame(list(s.SavReader('C:\\\\Users\\\\Sam Cannon\\\\Desktop\\\\R\\\\Data Sets\\\\new_datasets_7e\\\\new_datasets_7e\\\\Lesson 25 Data File 1.sav')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df = df.set_axis(['Group', 'Difference'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group  Difference\n",
       "0     1.0        12.0\n",
       "1     1.0        -2.0\n",
       "2     1.0         9.0\n",
       "3     1.0         3.0\n",
       "4     1.0         3.0\n",
       "5     1.0         0.0\n",
       "6     1.0         3.0\n",
       "7     1.0         2.0\n",
       "8     1.0         4.0\n",
       "9     1.0         1.0\n",
       "10    2.0        -2.0\n",
       "11    2.0        -3.0\n",
       "12    2.0         3.0\n",
       "13    2.0        -2.0\n",
       "14    2.0         0.0\n",
       "15    2.0        -4.0\n",
       "16    2.0        -3.0\n",
       "17    2.0         5.0\n",
       "18    2.0        -9.0\n",
       "19    2.0        -6.0\n",
       "20    3.0         6.0\n",
       "21    3.0        -7.0\n",
       "22    3.0        -6.0\n",
       "23    3.0        -6.0\n",
       "24    3.0        -6.0\n",
       "25    3.0        -4.0\n",
       "26    3.0        -2.0\n",
       "27    3.0        -6.0\n",
       "28    3.0         6.0\n",
       "29    3.0         5.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ANOVA with statsmodels__\n",
    "\n",
    "- Code was adapted from: https://www.marsja.se/four-ways-to-conduct-one-way-anovas-using-python/ and https://pythonfordatascience.org/anova-python/#test \n",
    "- explanations were taken directly from these websites as well, the data is the only difference here\n",
    "- Using statsmodels, we get a bit more information and enter the model as a regression formula. The general input using this method looks like this:\n",
    "    - model_name = ols('outcome_variable ~ group1 + group2 + groupN', data=your_data).fit()\n",
    "\n",
    "- If you dummy code the groups, you have to not include 1 of the groups in the formula. This group’s data will still get captured in the model’s intercept and is the base (control) group. If you use the following method of entering the formula Python takes care of this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum_sq    df         F   PR(>F)\n",
      "C(Group)   205.4   2.0  4.835891  0.01603\n",
      "Residual   573.4  27.0       NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#have to use C() with the control group\n",
    "mod = ols('Difference ~ C(Group)', data=df).fit()\n",
    "                \n",
    "aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break down this ANOVA table. The dose row is the between groups effect which is the overall experimental effect. The sum of squares for the model (SSM; value 20.133 in the table) is how much variance is explained by our model. The current model explains a significant amount of variance, F(2,12)= 5.12, p < 0.05. The residual row is the unsystematic variation in the data (SSR; also called the unexplained variance; value 23.600 in the table). In this case, the unsystematic variation represents the natural individual differences in libido and natural different reactions to the drug, Difficile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Difference</td>    <th>  R-squared:         </th> <td>   0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 22 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>0.0160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:20:45</td>     <th>  Log-Likelihood:    </th> <td> -86.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   179.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    27</td>      <th>  BIC:               </th> <td>   183.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    3.5000</td> <td>    1.457</td> <td>    2.402</td> <td> 0.023</td> <td>    0.510</td> <td>    6.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Group)[T.2.0]</th> <td>   -5.6000</td> <td>    2.061</td> <td>   -2.717</td> <td> 0.011</td> <td>   -9.829</td> <td>   -1.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Group)[T.3.0]</th> <td>   -5.5000</td> <td>    2.061</td> <td>   -2.669</td> <td> 0.013</td> <td>   -9.729</td> <td>   -1.271</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.156</td> <th>  Durbin-Watson:     </th> <td>   2.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.206</td> <th>  Jarque-Bera (JB):  </th> <td>   2.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.652</td> <th>  Prob(JB):          </th> <td>   0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.304</td> <th>  Cond. No.          </th> <td>    3.73</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             Difference   R-squared:                       0.264\n",
       "Model:                            OLS   Adj. R-squared:                  0.209\n",
       "Method:                 Least Squares   F-statistic:                     4.836\n",
       "Date:                Mon, 22 Jul 2019   Prob (F-statistic):             0.0160\n",
       "Time:                        14:20:45   Log-Likelihood:                -86.824\n",
       "No. Observations:                  30   AIC:                             179.6\n",
       "Df Residuals:                      27   BIC:                             183.9\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           3.5000      1.457      2.402      0.023       0.510       6.490\n",
       "C(Group)[T.2.0]    -5.6000      2.061     -2.717      0.011      -9.829      -1.371\n",
       "C(Group)[T.3.0]    -5.5000      2.061     -2.669      0.013      -9.729      -1.271\n",
       "==============================================================================\n",
       "Omnibus:                        3.156   Durbin-Watson:                   2.135\n",
       "Prob(Omnibus):                  0.206   Jarque-Bera (JB):                2.729\n",
       "Skew:                           0.652   Prob(JB):                        0.256\n",
       "Kurtosis:                       2.304   Cond. No.                         3.73\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "      <th>eta_sq</th>\n",
       "      <th>omega_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(Group)</th>\n",
       "      <td>205.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.700000</td>\n",
       "      <td>4.835891</td>\n",
       "      <td>0.01603</td>\n",
       "      <td>0.263739</td>\n",
       "      <td>0.203648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>573.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.237037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sum_sq    df     mean_sq         F   PR(>F)    eta_sq  omega_sq\n",
       "C(Group)   205.4   2.0  102.700000  4.835891  0.01603  0.263739  0.203648\n",
       "Residual   573.4  27.0   21.237037       NaN      NaN       NaN       NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def anova_table(aov):\n",
    "    aov['mean_sq'] = aov[:]['sum_sq']/aov[:]['df']\n",
    "    \n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    \n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*aov['mean_sq'][-1]))/(sum(aov['sum_sq'])+aov['mean_sq'][-1])\n",
    "    \n",
    "    cols = ['sum_sq', 'df', 'mean_sq', 'F', 'PR(>F)', 'eta_sq', 'omega_sq']\n",
    "    aov = aov[cols]\n",
    "    return aov\n",
    "\n",
    "anova_table(aov_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATING MODEL EFFECT SIZE\n",
    "Something that is useful is the effect size. The effect size tells us how much of an impact the experiment will have in the real world. There are a few different effect sizes one can use: eta squared (?2), and omega squared (?2). Omega squared is considered a better measure of effect size than eta squared because it is unbiased in it’s calculation.\n",
    "\n",
    "Something to note, for some reason R2 is called eta squared within the ANOVA framework. They are the same thing. R2 is a measure of how much variance is explained by the model and is calculated by taking the explained variance (SSM) and dividing it by the total variance (SST; also called total sum of squares). With the total variance (SST) equaling the sum of squares for the model (SSM) plus the sum of square for the residual (SSR). Thus making the equation for R2 and eta squared:\n",
    "\n",
    "R2 and eta squared = SSM/SST\n",
    "R2 and eta squared = 20.133/43.733 = 0.460\n",
    "\n",
    "That means the current model accounts for 46.0% of the variance in contributing to libido. Like just mentioned, within the ANOVA framework, R2 is also called eta squared, and can be interpreted as the amount of explained variance, as well as an effect size measure.\n",
    "\n",
    "Another thing we need to calculate is the mean squares. The mean squares is desired because it eliminates the bias present in the SSM and SSR, and it is also used to calculate the F-statistic and omega squared. SSM and SSR are biased because they are influenced by the number of values summed to calculated them. To calculate the mean squares, one divides the sum of squares (SSM and SSR) by the degrees of freedom respectively.\n",
    "\n",
    "MSM= SSM/dfM = 20.135/2 = 10.067\n",
    "MSR= SSR/dfR = 23.60/12 = 1.967\n",
    "\n",
    "MSM is the average amount of variance explained by the current model, MSR is the average amount of variance unexplained by the current model. The ratio of MSM to MSR is used to calculate the F-statistic. We don’t need to do this since we already have it, but it’s nice to understand where the numbers come from!\n",
    "\n",
    "MSM/MSR = 10.067/1.967 = 5.118\n",
    "\n",
    "The following function calculates the effect sizes mentioned, as well as the mean squares and updates the table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jb': 2.728816783985189,\n",
       " 'jbpv': 0.25553180594136615,\n",
       " 'skew': 0.6516900447777306,\n",
       " 'kurtosis': 2.3041165547747604,\n",
       " 'omni': 3.15619079399286,\n",
       " 'omnipv': 0.20636777282150953,\n",
       " 'condno': 3.7320508075688776,\n",
       " 'mineigval': 2.679491924311227}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.diagn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the same diagnostics from the bottom of the regression table from before. The Durban-Watson tests is to detect the presence of autocorrelation (not provided when calling diagnostics this way), Jarque-Bera (jb; jbpv is p-value) tests the assumption of normality, Omnibus (omni; omnipv is p-value) tests the assumption of homogeneity of variance, and the Condition Number (condno) assess multicollinearity. Condition Number values over 20 are indicative of multicollinearity.\n",
    "\n",
    "If the omnibus test were to be significant, an option on how to handle it would be to use a heteroscedasticity corrected coefficient covariance matrix in the .anova_lm() method. This corrects the calculations to account for the heteroscedasticity present. More information on the method can be found on it’s official documentation page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Levene Test__\n",
    "- check for equal variances, p>.05 means we are good and variances are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.5360670457946722, pvalue=0.5911429509394336)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "stats.levene(df['Difference'][df['Group'] == 1],\n",
    "             df['Difference'][df['Group'] == 2],\n",
    "             df['Difference'][df['Group'] == 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Shapiro Test for Normality__\n",
    "- p > .05 means residuals are normally distributed, t-stat on the left, p-value on the right, our p is less than .05, so the resioduals are not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9026545286178589, 0.009759031236171722)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.shapiro(mod.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Post-hoc Testing__\n",
    "The overall model was significant, now to test which groups differ. Deciding which groups to compare should be theory driven. There are a few different techniques that can be used. Each of these techniques have different ways of controlling for familywise error rate. 3 common methods are:\n",
    "\n",
    "Fisher’s Least Significant Difference (LSD): Take the groups you want to compare and conduct multiple t-tests. This method requires that the ANOVA model be significant. This method is easy, but receives push back since it doesn’t account for familywise error rate. The argument is that since the overall model was significant, one is protected from increasing the familywise error rate.\n",
    "Bonferroni correction: Take the alpha the ANOVA was tested at, 0.05, then divide it by the number of planned comparisons. In this case, 0.05/3 = 0.0167. A post-hoc test would have to have an alpha level < 0.0167 to be considered significant. To test the groups, conduct multiple t-tests, but set the alpha value to the corrected value. This method is quick, but often considered too conservative.\n",
    "Tukey’s HSD: Method also controls for familywise error rate with a different method than Bonferroni, and is also considered conservative.\n",
    "There are many other techniques out there that can be used for post-hoc testing each with different guidelines for when they should be used, you are encouraged to learn about them!\n",
    "\n",
    "__TUKEY’S HSD POST-HOC COMPARISON__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD,FWER=0.05\n",
      "==============================================\n",
      "group1 group2 meandiff  lower    upper  reject\n",
      "----------------------------------------------\n",
      " 1.0    2.0     -5.6   -10.7089 -0.4911  True \n",
      " 1.0    3.0     -5.5   -10.6089 -0.3911  True \n",
      " 2.0    3.0     0.1    -5.0089   5.2089 False \n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "mc = MultiComparison(df['Difference'], df['Group'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tukey HSD post-hoc comparison test controls for type I error and maintains the familywise error rate at 0.05 (FWER= 0.05 top of the table). The group1 and group2 columns are the groups being compared, the meandiff column is the difference in means of the two groups being calculated as group2 – group1, the lower/upper columns are the lower/upper boundaries of the 95% confidence interval, and the reject column states whether or not the null hypothesis should be rejected. Unfortunately, this method currently does not provide the t-statistic so treatment effect size cannot be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BONFERRONI CORRECTION POST-HOC COMPARISON__\n",
    "First the corrected p-value needs to be calculated. This can be done using the formula:\n",
    "\n",
    "p-value/# of comparisons = 0.05/3 = 0.01667\n",
    "\n",
    "Now the t-tests that are conducted have to have a p-value less than 0.01667 in order to be considered significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.050011616952708, pvalue=0.0068922723946386885)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.532474592535423, pvalue=0.020849157649945604)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.046351743495682274, pvalue=0.9635402876217463)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(df['Difference'][df['Group'] == 1], df['Difference'][df['Group'] == 2])\n",
    "\n",
    "\n",
    "stats.ttest_ind(df['Difference'][df['Group'] == 1], df['Difference'][df['Group'] == 3])\n",
    "\n",
    "\n",
    "stats.ttest_ind(df['Difference'][df['Group'] == 2], df['Difference'][df['Group'] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
